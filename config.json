{
    "llm_model_name_or_path": "HuggingFaceTB/SmolLM2-360M-Instruct",
    "cache_dir": null,
    "data_path": "mls_eng_10k",
    "optim": "adamw_torch_fused",
    "model_max_length": 2048,
    "logging_steps": 10,
    "eval_steps": 100,
    "save_steps": 100,
    "report_to": "wandb",
    "run_name": "tts_experiment_01",
    "gradient_checkpointing": true,
    "lr_scheduler_type": "cosine",
    "per_device_train_batch_size": 256,
    "per_device_eval_batch_size": 256,
    "weight_decay": 0.01,
    "learning_rate": 5e-5,
    "output_dir": "./output"
  }
  